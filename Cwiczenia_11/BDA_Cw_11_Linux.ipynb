{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 47: Reading Data from a CSV File Using the PySpark Object\n",
    "\n",
    "# 1. import all the required packages:\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from sklearn.base import TransformerMixin\n",
    "import random\n",
    "# import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Import all the libraries required for Spark to build the Spark session:\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('ml-bank').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create and read the data from the CSV file using the Spark object, as illustrated:\n",
    "\n",
    "\n",
    "df_csv = spark.read.csv('bank.csv', sep=';', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=30, job='unemployed', marital='married', education='primary', default='no', balance=1787, housing='no', loan='no', contact='cellular', day=19, month='oct', duration=79, campaign=1, pdays=-1, previous=0, poutcome='unknown', y='no'),\n",
       " Row(age=33, job='services', marital='married', education='secondary', default='no', balance=4789, housing='yes', loan='yes', contact='cellular', day=11, month='may', duration=220, campaign=1, pdays=339, previous=4, poutcome='failure', y='no'),\n",
       " Row(age=35, job='management', marital='single', education='tertiary', default='no', balance=1350, housing='yes', loan='no', contact='cellular', day=16, month='apr', duration=185, campaign=1, pdays=330, previous=1, poutcome='failure', y='no'),\n",
       " Row(age=30, job='management', marital='married', education='tertiary', default='no', balance=1476, housing='yes', loan='yes', contact='unknown', day=3, month='jun', duration=199, campaign=4, pdays=-1, previous=0, poutcome='unknown', y='no'),\n",
       " Row(age=59, job='blue-collar', marital='married', education='secondary', default='no', balance=0, housing='yes', loan='no', contact='unknown', day=5, month='may', duration=226, campaign=1, pdays=-1, previous=0, poutcome='unknown', y='no')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Now let's print the first five rows from the Spark object using the following command:\n",
    "\n",
    "df_csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv1 = df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. The previous output is unstructured.\n",
    "# Let's first identify the data types to proceed to get the structured data.\n",
    "# Use the following command to print the datatype of each column:\n",
    "\n",
    "df_csv1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4521"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Now let's calculate the total number of rows and columns with names\n",
    "# to get a clear idea of the data we have:\n",
    "\n",
    "df_csv1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17,\n",
       " ['age',\n",
       "  'job',\n",
       "  'marital',\n",
       "  'education',\n",
       "  'default',\n",
       "  'balance',\n",
       "  'housing',\n",
       "  'loan',\n",
       "  'contact',\n",
       "  'day',\n",
       "  'month',\n",
       "  'duration',\n",
       "  'campaign',\n",
       "  'pdays',\n",
       "  'previous',\n",
       "  'poutcome',\n",
       "  'y'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_csv1.columns), df_csv1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, age: string, job: string, marital: string, education: string, default: string, balance: string, housing: string, loan: string, contact: string, day: string, month: string, duration: string, campaign: string, pdays: string, previous: string, poutcome: string, y: string]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Print the summary statistics for the DataFrame using the following command:\n",
    "\n",
    "df_csv1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+--------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+----+\n",
      "|summary|               age|    job| marital|education|default|           balance|housing|loan| contact|               day|month|          duration|          campaign|             pdays|          previous|poutcome|   y|\n",
      "+-------+------------------+-------+--------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+----+\n",
      "|  count|              4521|   4521|    4521|     4521|   4521|              4521|   4521|4521|    4521|              4521| 4521|              4521|              4521|              4521|              4521|    4521|4521|\n",
      "|   mean| 41.17009511170095|   null|    null|     null|   null|1422.6578190665782|   null|null|    null|15.915284229152842| null|263.96129174961294| 2.793629727936297|39.766644547666445|0.5425790754257908|    null|null|\n",
      "| stddev|10.576210958711263|   null|    null|     null|   null|3009.6381424673395|   null|null|    null| 8.247667327229934| null|259.85663262468216|3.1098066601885823|100.12112444301656|1.6935623506071211|    null|null|\n",
      "|    min|                19| admin.|divorced|  primary|     no|             -3313|     no|  no|cellular|                 1|  apr|                 4|                 1|                -1|                 0| failure|  no|\n",
      "|    max|                87|unknown|  single|  unknown|    yes|             71188|    yes| yes| unknown|                31|  sep|              3025|                50|               871|                25| unknown| yes|\n",
      "+-------+------------------+-------+--------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv1.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|balance|  y|\n",
      "+-------+---+\n",
      "|   1787| no|\n",
      "|   4789| no|\n",
      "|   1350| no|\n",
      "|   1476| no|\n",
      "|      0| no|\n",
      "+-------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8. To select multiple columns from a DataFrame, we can use the \n",
    "# df_csv1.select('col1', 'col2', 'col3') function.\n",
    "# For example, let's select the first five rows from the balance \n",
    "# and y columns using the following command:\n",
    "\n",
    "df_csv1.select('balance','y').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+------+\n",
      "|y_marital|divorced|married|single|\n",
      "+---------+--------+-------+------+\n",
      "|      yes|      77|    277|   167|\n",
      "|       no|     451|   2520|  1029|\n",
      "+---------+--------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. To identify the relation between two variables in terms of their frequency of levels,\n",
    "# crosstab can be used.\n",
    "# To derive crosstab between two columns, we can use the df_csv1.crosstab('col1', col2)\n",
    "# function. \n",
    "# Crosstab iscarried out between two categorical variables and not between\n",
    "# numerical variables:\n",
    "\n",
    "df_csv1.crosstab('y', 'marital').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Now, let's add a new column to the dataset.\n",
    "\n",
    "# We are using here sample() method. It is used for taking samples from the large \n",
    "# dataset.\n",
    "# Sampling is the process of determining a representative subgroup from the dataset \n",
    "# for \n",
    "# a specified casestudy. Sampling stands for crucial research and business decision \n",
    "# results.\n",
    "# For this reason, it is essential touse the most appropriate and useful sampling \n",
    "# methods\n",
    "# with the provided technology. This article is mainly for data scientists and data \n",
    "# engineers\n",
    "# looking to use the newest enhancements of Apache Spark in the sub-area of sampling.\n",
    "\n",
    "# If the sample() is used, simple random sampling is applied, and each element in the \n",
    "# dataset has an equal chance of being selected. Variable selection is made from the\n",
    "# dataset at the fraction rate specified randomly without grouping or clustering on\n",
    "# the basis of any variable. This method works with 3 parameters.\n",
    "\n",
    "# The withReplacement parameter is set to False by default, so the element can only be \n",
    "# selected as a sample once. If this value is changed to True, it is possible to \n",
    "# select\n",
    "# a sample value in the same sampling again.\n",
    "\n",
    "# There may be a slight difference between the number of withReplacement = True \n",
    "# and \n",
    "# withReplacement = False since the elements can be selected more than once.\n",
    "# Another parameter, the fraction field that is required to be filled, and as \n",
    "# stated in \n",
    "# Sparkâ€™s official documentation, it may not be divided by the specified \n",
    "# percentage value.\n",
    "# If any number is assigned to the seed field, it can be thought of as \n",
    "# assigning a special \n",
    "# id to that sampling. In this way, the same sample is selected every \n",
    "# time the script is run.\n",
    "# If this value is left as None, a different sampling group is created \n",
    "# each time.\n",
    "\n",
    "\n",
    "sample1 = df_csv1.sample(False, 0.2, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "935"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2 = sample1.withColumn('balance_new',sample1.balance/2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|balance|balance_new|\n",
      "+-------+-----------+\n",
      "|    147|       73.5|\n",
      "|   4073|     2036.5|\n",
      "|   -221|     -110.5|\n",
      "|    627|      313.5|\n",
      "|    229|      114.5|\n",
      "|   3935|     1967.5|\n",
      "|   -849|     -424.5|\n",
      "|    844|      422.0|\n",
      "|    101|       50.5|\n",
      "|   1355|      677.5|\n",
      "+-------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample2.select('balance','balance_new').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Drop the newly created column using the following command:\n",
    "\n",
    "sample2 = sample2.drop('balance_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 49: Creating and Merging Two DataFrames\n",
    "\n",
    "# 5. Add new, ID column. Generate it's values using method:\n",
    "from pyspark.sql.functions import monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_id = df_csv1.withColumn('ID',monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Now, to merge the two DataFrames using the primary key (ID), first, we will have to\n",
    "# split it into two DataFrames. Schemas of the dataframes should be as follows:\n",
    "# train_with_id1('ID' and all columns except 'balance')\n",
    "# train_with_id1('ID','balance')\n",
    "\n",
    "train_df_id2 = train_df_id.select('ID','balance')\n",
    "train_df_id1 = train_df_id.drop('balance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Merge train_with_id1 and train_with_id2 using the following command:\n",
    "\n",
    "train_merged = train_df_id1.join(train_df_id2, on=['ID'], how='left_outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 50: Subsetting the DataFrame\n",
    "\n",
    "# 1. Make a subset with records, where balance value is in range between 0 and 2000.\n",
    "\n",
    "train_subset = df_csv1.filter((df_csv1.balance > 0.0) & (df_csv1.balance < 2000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1787</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>oct</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1350</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>apr</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1476</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>747</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>23</td>\n",
       "      <td>feb</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>176</td>\n",
       "      <td>3</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>self-employed</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>307</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>14</td>\n",
       "      <td>may</td>\n",
       "      <td>341</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>2</td>\n",
       "      <td>other</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0              1        2         3   4     5    6    7         8   9   \\\n",
       "0  30     unemployed  married   primary  no  1787   no   no  cellular  19   \n",
       "1  35     management   single  tertiary  no  1350  yes   no  cellular  16   \n",
       "2  30     management  married  tertiary  no  1476  yes  yes   unknown   3   \n",
       "3  35     management   single  tertiary  no   747   no   no  cellular  23   \n",
       "4  36  self-employed  married  tertiary  no   307  yes   no  cellular  14   \n",
       "\n",
       "    10   11  12   13  14       15  16  \n",
       "0  oct   79   1   -1   0  unknown  no  \n",
       "1  apr  185   1  330   1  failure  no  \n",
       "2  jun  199   4   -1   0  unknown  no  \n",
       "3  feb  141   2  176   3  failure  no  \n",
       "4  may  341   1  330   2    other  no  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_subset.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
